











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/Jangrae/csv/master/diabetes.csv'
data = pd.read_csv(path)





# 데이터 살펴보기
data.head()





# 기술통계 확인
data.describe()








# Target 확인
target = 'Outcome'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[:, target]





# 라이브러리 불러오기
from sklearn.model_selection import train_test_split

# 학습용, 평가용 데이터 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)








# 불러오기
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = DecisionTreeClassifier(random_state=1)

# 검증하기
cv_score = cross_val_score(model, x_train, y_train, cv=10) 

# 확인 
print(cv_score) # 정확도 # ex) 회귀에서는 R2
print('평균:', cv_score.mean())
print('표준편차:', cv_score.std())

# 예측 결과 저장
result = {}
result['Decision Tree'] = cv_score.mean()

# 확인
print(result)





# 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = KNeighborsClassifier()

# 검증하기
cv_score = cross_val_score(model, x_train_s, y_train, cv=10)

# 확인
print(cv_score)
print(cv_score.mean())

# 예측 결과 저장
result['KNN'] = cv_score.mean()
print(result)





# 불러오기
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# 선언하기
model = LogisticRegression()

# 검증하기
cv_score = cross_val_score(model, x_train, y_train, cv=10)

# 확인
print(cv_score)
print(cv_score.mean())

# 예측결과 저장
result['Logistic Regression'] = cv_score.mean()
print(result)





#plt.barh(y=result.keys(), width=result.values(), data=data)
plt.barh(y=list(result), width=result.values(), data=data)
plt.show()





from sklearn.metrics import confusion_matrix, classification_report
# 모델 선언
model = LogisticRegression()

# 학습
model.fit(x_train, y_train)

# 예측
y_pred = model.predict(x_test)

# 평가
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))









