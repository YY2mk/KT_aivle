











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/jangrae/csv/master/diabetes.csv'
data = pd.read_csv(path)





# 상위 몇 개 행 확인
data.head()





# 기술통계 확인
data.describe()


# 범주값 개수 확인
data['Outcome'].value_counts()


# 상관관계 확인
data.corr(numeric_only=True)








# target 확인
target = 'Outcome'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[:, target]





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)


plt.boxplot(x_train, vert=False, labels=list(x))
plt.show()





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)


plt.boxplot(x_train_s, vert=False, labels=list(x))
plt.show()





# 1단계: 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_absolute_error, r2_score


# 2단계: 선언하기
model = KNeighborsClassifier()


# 3단계: 학습하기
model.fit(x_train, y_train)





# 4단계 예측하기
y_pred = model.predict(x_test)


# 5단계: 평가하기
print('MAE:', mean_absolute_error(y_test, y_pred))
print('R2:', r2_score(y_test, y_pred))


# 정규화 후


# 4단계 예측하기
y_pred = model.predict(x_test_s)


# 5단계: 평가하기
print('MAE:', mean_absolute_error(y_test, y_pred))
print('R2:', r2_score(y_test, y_pred))



