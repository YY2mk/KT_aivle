











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'


# 데이터 불러오기
path = 'https://raw.githubusercontent.com/jangrae/csv/master/Attrition_simple2.csv'
data = pd.read_csv(path)





# 데이터 살펴보기
data.head()





# 기술통계 확인
data.describe().T








# 제거 대상
drop_cols = ['EmployeeNumber']

# 변수 제거
data = data.drop(drop_cols, axis=1)

# 확인
data





# target 확인
target = 'Attrition'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[:, target]





data.info()


# 가변수화 대상
dumm_cols = ['Gender', 'MaritalStatus', 'OverTime']

# 가변수화
x = pd.get_dummies(x, columns=dumm_cols, drop_first=True, dtype=int)

# 확인
x





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 학습용, 평가용 7:3 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

# 학습용, 검증용 8:2 분리
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)





# xgboost 설치
# !pip install xgboost


# lightgbm 설치
# !pip install lightgbm





# 불러오기
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import *





# 매개변수 범위('n_neighbors': range(1, 21))
param = {'n_neighbors': range(1, 21)}

# 모델 선언
model_knn = KNeighborsClassifier()

# 매개변수와 성능 확인
model_knn = GridSearchCV(model_knn,
                         param,
                         cv=5,
                         scoring='accuracy'
                        )

# 학습
model_knn.fit(x_train_s, y_train)





# 예측하기
y_pred = model_knn.predict(x_val)

# 검증하기
print(confusion_matrix(y_val, y_pred))
print(classification_report(y_val, y_pred))


# 성능정보 수집(Accuracy Score)
result = {}
result['knn'] = accuracy_score(y_val, y_pred)
print(result)





# 매개변수 범위('max_depth': range(1, 21))
param = {'max_depth': range(1, 21)}

# 모델 선언
model_dt = DecisionTreeClassifier()

# 매개변수와 성능 확인
model_dt = GridSearchCV(model_dt,
                         param,
                         cv=5,
                         scoring='accuracy'
                        )

# 학습
model_dt.fit(x_train, y_train)





# 예측하기
y_pred = model_dt.predict(x_val)

# 검증하기
print(confusion_matrix(y_val, y_pred))
print(classification_report(y_val, y_pred))


# 성능정보 수집(Accuracy Score)
result['Decision Tree'] = accuracy_score(y_val, y_pred)
print(result)





# 매개변수 범위('max_depth': range(1, 11), 'n_estimators': range(80, 121, 10))
param = {'max_depth': range(1, 11), 'n_estimators': range(80, 121, 10)}

# 모델 선언
model_rf = RandomForestClassifier()

# 매개변수와 성능 확인
model_rf = GridSearchCV(model_rf,
                         param,
                         cv=5,
                         scoring='accuracy'
                        )

# 학습
model_rf.fit(x_train_s, y_train)





# 예측하기
y_pred = model_rf.predict(x_val)

# 검증하기
print(confusion_matrix(y_val, y_pred))
print(classification_report(y_val, y_pred))


# 성능정보 수집(Accuracy Score)
result['Random Forest'] = accuracy_score(y_val, y_pred)
print(result)





# 매개변수 범위('max_depth': range(1, 11), 'n_estimators': range(80, 121, 10))
param = {'max_depth': range(1, 11), 'n_estimators': range(80, 121, 10)}

# 모델 선언
model_lgbm = LGBMClassifier()

# 매개변수와 성능 확인
model_lgbm = GridSearchCV(model_lgbm,
                         param,
                         cv=5,
                         scoring='accuracy'
                        )

# 학습
model_lgbm.fit(x_train_s, y_train)





# 예측하기
y_pred_lgbm = model_rf.predict(x_val)

# 검증하기
print(confusion_matrix(y_val, y_pred))
print(classification_report(y_val, y_pred))


# 성능정보 수집(Accuracy Score)
result['Random Forest'] = accuracy_score(y_val, y_pred)
print(result)





# 데이터프레임 만들기
df = pd.DataFrame()
df['name'] = result.keys()
df['accuracy'] = result.values()

# 확인
df





# 예측하기
y_pred = model_rf.predict(x_test)


# 평가하기
print(confusion_matrix(y_test, y_pred))
print(r2_score(y_test, y_pred))





# 데이터프레임 만들기




# 시각화
plt.barh(y=list(x), width=model_rf.feature_importances_)
plt.show()



