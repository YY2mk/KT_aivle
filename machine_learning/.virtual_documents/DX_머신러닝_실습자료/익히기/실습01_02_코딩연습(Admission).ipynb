














# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/Jangrae/csv/master/admission_simple.csv'
data = pd.read_csv(path)








# 상/하위 몇 개 행 확인
data.head()





# 하위 몇 개 행 확인
data.tail()


# 변수 확인
data.info()


# 기술통계 확인
data.describe().T


# 상관관계 확인
data.corr()


# 상관관계 시각화
sns.heatmap(data.corr(), annot=True, cbar=False)
plt.show()


sns.countplot(x=data['ADMIT'])
plt.show()


sns.histplot(x=data['GRE'], hue=data['ADMIT'],bins=30)
plt.show()











# target 확인
target = 'ADMIT'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[:, target]





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1, stratify=y)


# 데이터 분포 확인
print(y_train.value_counts(normalize=True))
print(y_test.value_counts(normalize=True))











# 1단계: 불러오기
from sklearn.neighbors import KNeighborsClassifier #최근접
from sklearn.metrics import accuracy_score


# 2단계: 선언하기
model = KNeighborsClassifier()


# 3단계: 학습하기
model.fit(x_train, y_train)


# 4단계: 예측하기
y_pred = model.predict(x_test)


print(y_test.values[:20])
print(y_pred[:20])


# 5단계: 평가하기
print('accuracy_score', accuracy_score(y_test, y_pred)) # 86% 


y_base = np.array([y_train.mode()[0]] * len(y_test))


print('accuracy_score', accuracy_score(y_test, y_base)) # base 56%






