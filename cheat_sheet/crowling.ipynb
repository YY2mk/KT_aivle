{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 경고 문구 안뜨게 해주는 설정\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 방식\n",
    "page_size, page = 30, 1 \n",
    "url = f'https://m.stock.naver.com/api/index/KOSPI/price?pageSize={page_size}&page={page}' # 네이버 코스피 지수 \n",
    "\n",
    "response = requests.get(url) # 서버에 데이터 요청\n",
    "response\n",
    "\n",
    "data = response.json() #리스트로 바꿔줌 \n",
    "\n",
    "cols = ['localTradedAt', 'closePrice'] # 원하는 컬럼만 데이터 프레임으로 출력\n",
    "df = pd.DataFrame(data)[cols] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 만듦\n",
    "def stock_price(code='KOSPI', page_size=60, page=1):\n",
    "    # 1. URL\n",
    "    url = f'https://m.stock.naver.com/api/index/{code}/price?pageSize={page_size}&page={page}'\n",
    "    # 2. request(url)\n",
    "    response = requests.get(url)\n",
    "    # 3. parsing json\n",
    "    data = response.json()\n",
    "    # 4. 데이터프레임 \n",
    "    cols = ['localTradedAt', 'closePrice']\n",
    "    df = pd.DataFrame(data)[cols]\n",
    "    #pd.DataFrame(response.json())[['localTradedAt', 'closePrice']] # 한줄로 줄일 수 있다\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. URL\n",
    "url = 'https://finance.daum.net/api/exchanges/summaries' # 다음 환율 \n",
    "\n",
    "# Cookie, Referer, User-Agent에서 결정 남 # 403이 나올 때 \n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',\n",
    "          'Referer': 'https://finance.daum.net/exchanges',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. request -> response\n",
    "response = requests.get(url, headers=headers)\n",
    "response\n",
    "\n",
    "# 3. parsing : json(str) -> DataFrame\n",
    "data = response.json()['data']\n",
    "df = pd.DataFrame(data)[['symbolCode', 'currencyCode', 'currencyName', 'basePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 카카오 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카카오 API\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REST_API_KEY #카카오 # https://developers.kakao.com/\n",
    "REST_API_KEY = '884c61e51fd621797d2d5501a7223173'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.kakao.com/docs/latest/ko/kogpt/rest-api #request-request-query \n",
    "# 1. document : url, headers, params\n",
    "prompt = '원자폭탄을 발명한 사람은'\n",
    "url = 'https://api.kakaobrain.com/v1/inference/kogpt/generation'\n",
    "params = {'prompt': prompt, 'max_tokens': 50}\n",
    "headers = { 'Content-Type': 'application/json', 'Authorization': f'KakaoAK {REST_API_KEY}'}\n",
    "\n",
    "# 2. request(url, headers, params) - > response(data) : json(str)\n",
    "response = requests.post(url, json.dumps(params), headers=headers)\n",
    "\n",
    "# 3. json(str) : text로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 언어는 인코딩해서 데이터 변환\n",
    "# 한글 일 떄\n",
    "json.dumps(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수만들기\n",
    "def kogpt_api(prompt, command='', max_tokens=128, temperature=1, n=1):\n",
    "    headers = {'Authorization': f'KakaoAK {REST_API_KEY}', 'Content-Type': 'application/json'}\n",
    "    params = {'prompt': prompt + command, 'max_tokens': max_tokens, 'temperature': temperature, 'n': n}\n",
    "    response = requests.post(url, json.dumps(params), headers=headers)\n",
    "    results = response.json()\n",
    "    results = results['generations']\n",
    "    return [result['text'] for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''상품 후기를 긍정 또는 부정으로 분류합니다.\n",
    "가격대비좀 부족한게많은듯=부정\n",
    "재구매 친구들이 좋은 향 난다고 해요=긍정\n",
    "ㅠㅠ약간 후회가 됩니다..=부정\n",
    "이전에 먹고 만족해서 재구매합니다=긍정\n",
    "튼튼하고 잘 쓸수 있을 것 같습니다. 이 가격에 이 퀄리티면 훌륭하죠='''\n",
    "results = kogpt_api(prompt, max_tokens=1, temperature=0.4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스 한줄 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "미국의 생성형 AI(인공지능) 모델·서비스 개발사 오픈AI(OpenAI)를 상대로 제기된 소송이 누적되고 있다. 쟁점 또한 AI 자료 학습부터 오픈소스 공개까지 전선이 전방위로 확산되는 모양새다.\n",
    "5일 IT(정보기술) 업계와 블룸버그 등 외신에 따르면 일론 머스크 테슬라 CEO(최고경영자)는 미국 캘리포니아주 샌프란시스코에서 오픈AI 법인과 창립자 샘 알트먼을 상대로 영리사업 중단과 AI 기술공개를 청구하는 소송을 지난달 29일(현지시간) 제기했다.\n",
    "머스크는 소장에서 오픈AI가 마이크로소프트(MS)와 체결한 수십억달러 규모의 파트너십과 사실상 비공개된 AI 기술정보 등에 비춰 오픈AI가 인류의 이익을 위해 AI 기술을 공개하기로 한 당초 창업 합의를 파기했다고 주장했다. 머스크는 2015년 알트먼 등과 오픈AI를 비영리단체 형태로 공동 설립한 뒤 2018년 이사회에서 물러났다.\n",
    "오픈AI를 둘러싼 법적 분쟁은 지난해 7월 미국 코미디언 겸 작가 사라 실버맨 등이 소송을 제기하면서 부각됐다. 언어모델 훈련 과정에서 창작물이 도용돼 저작권 침해, 저작권 관리정보 삭제에 따른 디지털 밀레니엄 저작권법(DMCA) 위반, 불공정 경쟁 등이 발생했다는 주장이다.\n",
    "다만 법원은 챗GPT로 생성된 결과물과 작가들의 원작물 사이의 유사성이 떨어진다는 이유로 지난달 실버맨 등의 청구를 상당 부분 기각한 채 심리를 진행 중이다. 이 사건과 별개로 '왕좌의 게임' 원작자 조지 R.R. 마틴을 비롯한 미국 작가조합은 지난해 9월 집단소송을 제기한 상태다.\n",
    "지난해 12월에는 미국 신문사 뉴욕타임스가 뉴스 저작권 침해를 주장하며 오픈AI와 오픈AI의 주요 투자자 MS를 상대로 소송을 제기했다. 뉴욕타임스 측은 회사 웹사이트에서 유료로 제공되던 기사 구절이 오픈AI의 서비스 챗GPT에 노출돼 이용자들이 우회적으로 기사를 무료로 읽을 수 있게 됐다고 주장했다. 오픈AI 측은 공개된 기사로 언어 모델을 훈련시켜 저작권법상 '공정이용 원칙'을 위반하지 않았다는 입장이다.\n",
    "업계에선 오픈AI가 지난달 15일 동영상 생성 AI 모델 '소라(Sora)'를 출시한 데 따라 법적 분쟁이 더 복잡해질 것이라는 전망도 나온다. AI 학습과 결과물 생성에 이용되는 데이터의 종류가 기존 언어모델보다 다양하고, 학습된 데이터의 원작자는 저작권을 주장할 여지가 있지만 AI로 결과물을 산출한 주체는 저작권을 주장하기 어려운 탓이다.\n",
    "법무법인 화우 정보보호센터는 지난달 29일 \"데이터를 입력한 주체는 권리침해 등에 대해 책임을 질 가능성이 존재하므로 사전에 입력 데이터에 대한 검수 절차를 마련할 필요가 있다\"고 밝혔다. 또 \"저작권에 관련해선 현행 저작권법과 유관기관은 인간의 창작적 개입이 없는 산출물에 대한 저작권 등록을 불허하므로 사람과 AI 작업의 구별 등 등록기관 가이드와 별도의 입법을 확인할 필요가 있다\"고 덧붙였다.\n",
    "한줄 요약:'''\n",
    "results = kogpt_api(prompt, max_tokens=50, temperature=0.2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 질문에 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "의료 스타트업으로 구성된 원격의료산업협의회가 10월부터 열리는 국정감사 시기에 맞춰 국회와 정부에 비대면 진료법 근거 마련을 \n",
    "촉구하는 정책제안서를 제출한다. 코로나19 사태에 비대면 진료의 한시 허용으로 원격 진료, 의약품 배송 등 서비스가 속속 등장하는 \n",
    "가운데 제도화 논의를 서둘러야 한다는 목소리가 높아질 것으로 전망된다. 코리아스타트업포럼 산하 원격의료산업협의회는 '위드(with) 코로나' \n",
    "방역 체계 전환을 염두에 두고 비대면 진료 제도화 촉구를 위한 공동 대응 작업을 추진하고 있다. 협의회는 닥터나우, 엠디스퀘어, SH바이오, \n",
    "메디버디 등 의료 스타트업 13개사로 구성됐다. 협의회는 국정감사 시기를 겨냥해 국회와 주무 부처인 보건복지부에 비대면 진료의 법적 근거 마련을 \n",
    "촉구할 방침이다. 이를 위해 주요 의원실과 관련 의견을 교환하고 있다. 협의회는 궁극적으로 의료법과 약사법 개정이 필요하지만 의료법 테두리 안에서 \n",
    "시행령 개정 등으로도 비대면 진료 가능성과 대상·의료기관 등을 구체화할 수 있다는 복안이다. 복지부 장관령으로 비대면 진료 기간을 명시하는 방안 \n",
    "등을 통해 사업 리스크도 줄일 수 있다. 올해 안에 국내 방역체계 패러다임이 바뀔 것으로 예상되는 점도 비대면 진료 제도화의 필요성을 높이고 있다. \n",
    "최근 코로나19 백신 접종이 속도를 내면서 방역 당국은 위드 코로나 방역체계 전환을 고려하고 있다. 인구 대비 백신 접종 완료율이 70%가 되는 \n",
    "오는 10월 말에는 전환 논의가 수면 위로 뜰 것으로 보인다.\n",
    "정책제안서를 제출하는 시기는 언제인가?:'''\n",
    "results = kogpt_api(prompt, temperature=0.2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 응용 (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('covid.xlsx')\n",
    "summaries = [summary[0] for summary in summaries]\n",
    "df['summary'] = summaries\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = df['content'].apply(kogpt_api, command='한줄요약:', max_tokens=20, temperature=0.5)\n",
    "\n",
    "summaries = [summary[0] for summary in summaries]\n",
    "df['summary'] = summaries\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통합검색어 트렌드 API\n",
    "- https://datalab.naver.com/\n",
    "- https://datalab.naver.com/keyword/trendSearch.naver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Token 얻기\n",
    "- https://developers.naver.com\n",
    "- Request Token 얻기 : 애플리케이션등록 -> app_key 획득\n",
    "- app_key를 이용해서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ID = 'FsLBBcP5sy2z_RbPzNu4'\n",
    "client_ID_Secret = '2Ewi9HKdqC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통합검색어 트렌드 API¶\n",
    "- 서비스 : https://datalab.naver.com/keyword/trendSearch.naver\n",
    "- 내 애플리케이션 > dss 애플리케이션 > API 설정 > 데이터랩(검색어 트렌드) 추가\n",
    "- 사용법 : https://developers.naver.com/docs/serviceapi/datalab/search/search.md#통합-검색어-트렌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. document : url, headers, params\n",
    "url = 'https://openapi.naver.com/v1/datalab/search' # 요청 url\n",
    "params = {\n",
    "    'startDate': '2016-01-01',\n",
    "    'endDate': '2024-02-29',\n",
    "    'timeUnit': 'month',\n",
    "    'keywordGroups': [\n",
    "        {'groupName': '트위터', 'keywords': ['트위터', '트윗']},\n",
    "        {'groupName': '페이스북', 'keywords': ['페이스북', '페북']},\n",
    "        {'groupName': '인스타그램', 'keywords': ['인스타그램', '인스타']},]}\n",
    "\n",
    "headers = {'X-Naver-Client-Id': client_ID,\n",
    "           'X-Naver-Client-Secret': client_ID_Secret,\n",
    "           'Content-Type': 'application/json',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 2. request -> response : json(str)\n",
    "response = requests.post(url, json.dumps(params), headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. json(str) : DataFrame\n",
    "data1 = response.json()['results'][0]['data']\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. parsing\n",
    "data = response.json()['results']\n",
    "\n",
    "dfs = []\n",
    "for row in data:\n",
    "    df = pd.DataFrame(row['data'])\n",
    "    df['title'] = row['title'] # 트위터, 페이스북, 인스타그램\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "result_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = result_df.pivot(index='period', columns='title', values='ratio')\n",
    "pivot_df.reset_index(drop=False, inplace=True)\n",
    "pivot_df.columns = ['instagram', 'twitter', 'facebook']\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 시각화\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_df.plot(figsize=(20, 5))\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직방 원룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process\n",
    "    - 동이름으로 위도 경도 구하기\n",
    "    - 위도 경도로 geohash 알아내기\n",
    "    - geohash로 매물 아이디 가져오기\n",
    "    - 매물 아이디로 매물 정보 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 동이름으로 위도 경도 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr = '망원동'\n",
    "url = f'https://apis.zigbang.com/v2/search?leaseYn=N&q={addr}&serviceType=원룸'\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()['items'][0]\n",
    "\n",
    "#위도 경도\n",
    "lat, lng = data['lat'], data['lng']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 위도 경도로 geohash 알아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install geohash2\n",
    "!pip install geohash2\n",
    "import geohash2 # 위도, 경도의 점으로 부터 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision : 영역범위 : 커질수록 영역이 작아짐\n",
    "geohash = geohash2.encode(lat, lng, precision=5)\n",
    "geohash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. geohash로 매물 아이디 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://apis.zigbang.com/v2/items/oneroom?\\\n",
    "geohash={geohash}&depositMin=0&rentMin=0&salesTypes[0]=전세&salesTypes[1]=월세\\\n",
    "&domain=zigbang&checkAnyItemWithoutFilter=true'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = response.json()['items']\n",
    "ids = [item['itemId'] for item in items]\n",
    "len(ids), ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 매물 아이디로 매물 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://apis.zigbang.com/v2/items/list'\n",
    "params = {'domain': \"zigbang\",\n",
    "         'item_ids': ids}\n",
    "\n",
    "response = requests.post(url, params)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jib_data = pd.DataFrame(_data)\n",
    "df = jib_data[jib_data['address1'].str.contains(addr)].reset_index(drop=True)\n",
    "cols = ['item_id', 'sales_type', 'deposit', 'rent', 'size_m2', 'title', 'address']\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 겸 직방 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile zigbang.py\n",
    "import pandas as pd\n",
    "import requests\n",
    "import geohash2\n",
    "def oneroom(addr):\n",
    "    \n",
    "    url = f'https://apis.zigbang.com/v2/search?leaseYn=N&q={addr}&serviceType=원룸'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()['items'][0]\n",
    "    lat, lng = data['lat'], data['lng']\n",
    "    \n",
    "    geohash = geohash2.encode(lat, lng, precision=5)\n",
    "    \n",
    "    url = f'https://apis.zigbang.com/v2/items/oneroom?\\\n",
    "geohash={geohash}&depositMin=0&rentMin=0&salesTypes[0]=전세&salesTypes[1]=월세\\\n",
    "&domain=zigbang&checkAnyItemWithoutFilter=true'\n",
    "    response = requests.get(url)\n",
    "    items = response.json()['items']\n",
    "    ids = [item['itemId'] for item in items]\n",
    "    \n",
    "    url = 'https://apis.zigbang.com/v2/items/list'\n",
    "    params = {'domain': 'zigbang', 'item_ids': ids[:900]}\n",
    "    response = requests.post(url, params)\n",
    "    items = response.json()['items']\n",
    "    df = pd.DataFrame(items)\n",
    "    df = df[df['address1'].str.contains(addr)].reset_index(drop=True)\n",
    "    columns = ['item_id', 'address1', 'sales_type', 'deposit', 'rent', 'size_m2', 'title', 'manage_cost']\n",
    "    return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zigbang as zb\n",
    "zb.oneroom('도봉동')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 정적 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= '삼성전자'\n",
    "url = f'https://search.naver.com/search.naver?query={query}'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = BeautifulSoup(response.text, 'html.parser')\n",
    "type(dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select() : element 여러개 선택\n",
    "#  select_one() : element 한개 선택\n",
    "# 10개 선택 # 크롬 \n",
    "selector = '#nx_footer_related_keywords > div > div.related_srch > ul > li'\n",
    "elements = dom.select(selector)\n",
    "len(elements), elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [element.text.strip() for element in elements]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gmarket\n",
    "베스트 상품 200개 데이터 수집\n",
    "상품의 이미지 200개 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gmarket.co.kr/n/best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = BeautifulSoup(response.text, 'html.parser')\n",
    "type(dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200개 상품 선택 : select()\n",
    "elements = dom.select('#gBestWrap > div.best-list > ul > li')\n",
    "len(elements), elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 상품에서 데이터 추출 : select_one()\n",
    "element = elements[0]\n",
    "data = {'title':element.select_one('.itemname').text,\n",
    "       'img': 'http:' + element.select_one('.image__lazy').get('src')}\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for element in elements:\n",
    "    data = {'title':element.select_one('.itemname').text,\n",
    "       'img': 'http:' + element.select_one('.image__lazy').get('src'),\n",
    "        'price': element.select_one('.s-price').text}\n",
    "    items.append(data)\n",
    "    \n",
    "len(items), items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(items)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = df.loc[0, 'img']\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(link)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wb : write binary\n",
    "with open('data.png', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pillow : 이미지 전처리 패키지\n",
    "from PIL import Image as pil\n",
    "pil.open('data.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
