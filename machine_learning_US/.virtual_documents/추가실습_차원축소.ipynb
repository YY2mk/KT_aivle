








# 기본 라이브러리 가져오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import *
from sklearn.decomposition import PCA

from sklearn.preprocessing import StandardScaler, MinMaxScaler








data = pd.read_excel('bankrupt.xlsx')
data.head()


data.info()





target = 'target'

x = data.drop(target, axis = 1)
y = data[target]





x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .3, random_state = 20)





scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

# (옵션)데이터프레임 변환
x_train = pd.DataFrame(x_train, columns=list(x))








# 주성분을 최대값으로 결정
n =

# 주성분 분석 선언
pca =

# 만들고, 적용하기
x_train_pc =
x_val_pc =





# 칼럼이름 생성
column_names = [ 'PC'+str(i+1) for i in range(n) ]
column_names

# 데이터프레임으로 변환하기
x_train_pc = pd.DataFrame(x_train_pc, columns = column_names)
x_val_pc = pd.DataFrame(x_val_pc, columns = column_names)
x_train_pc





plt.plot(range(1,n+1),         , marker = '.')
plt.xlabel('No. of PC')
plt.grid()
plt.show()











sns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)
plt.grid()
plt.show()





plt.figure(figsize = (8, 8))
sns.heatmap(x_train.corr())


plt.figure(figsize = (8, 8))
sns.heatmap(x_train_pc.corr())











# 모델 선언
model0 =

# 학습






# 예측


# 평가







# 여러분이 선택한 주성분 개수
n =

# 데이터 준비
cols = column_names[:n]
x_train_pc_n = x_train_pc.loc[:, cols]
x_val_pc_n = x_val_pc.loc[:, cols]

# 모델 선언 및 학습
model_n =




# 예측


# 평가










from sklearn.manifold import TSNE


# 2차원으로 축소하기
tsne = TSNE(n_components = 2, random_state=20)
x_tsne = tsne.fit_transform(x)

# 사용의 편리함을 위해 DataFrame으로 변환
x_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])


x_tsne.shape





plt.figure(figsize=(6,6))
sns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)
plt.grid()
