








!pip install plotly
import plotly.graph_objects as go


# 기본 라이브러리 가져오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import *

from sklearn.datasets import load_breast_cancer, load_digits, load_iris, make_swiss_roll
from sklearn.preprocessing import MinMaxScaler

from sklearn.decomposition import PCA





# 럭비공 형태의 샘플 데이터 생성 함수
def generate_rugby_data(n_points=1000, a=1, b=1.5, c=2):
    phi = np.random.uniform(0, np.pi, n_points)
    theta = np.random.uniform(0, 2*np.pi, n_points)
    x = a * np.sin(phi) * np.cos(theta)
    y = b * np.sin(phi) * np.sin(theta)
    z = c * np.cos(phi)
    X = np.column_stack((x, y, z))
    return X

rugby = generate_rugby_data()

# 스위스롤 데이터
swiss_roll, _ = make_swiss_roll(n_samples=1000, noise=0.2)


# 3차원 스캐터 함수 생성
def my_3d_Scatter(X) :
    fig = go.Figure()
    fig.add_trace(go.Scatter3d(x=X[:, 0], y=X[:, 1], z=X[:, 2],
                           mode='markers', marker=dict(size=2, color='blue'),
                           name='Original Data'))

    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0),
                      scene=dict(xaxis_title='X Axis', yaxis_title='Y Axis', zaxis_title='Z Axis'))

    fig.show()











my_3d_Scatter(rugby)





# PCA를 이용하여 2개의 주성분으로 차원 축소
pca = PCA(n_components=2)
X_pca = pca.fit_transform(rugby)

# PCA 축소 데이터 조회
plt.scatter(X_pca[:, 0], X_pca[:, 1])
plt.grid()
plt.show()












my_3d_Scatter(swiss_roll)





# PCA를 이용하여 2개의 주성분으로 차원 축소
pca = PCA(n_components=2)
X_pca = pca.fit_transform(swiss_roll)

# PCA 축소 데이터 조회
plt.scatter(X_pca[:, 0], X_pca[:, 1])
plt.grid()
plt.show()












iris = pd.read_csv("https://raw.githubusercontent.com/DA4BAM/dataset/master/iris.csv")
target = 'Species'
x = iris.drop(target, axis = 1)
y = iris.loc[:, target]


x.head()





scaler = MinMaxScaler()
x2 = scaler.fit_transform(x)

# (옵션)데이터프레임 변환
x2 = pd.DataFrame(x2, columns= x.columns)





from sklearn.decomposition import PCA


# feature 수
x2.shape[1]





# 주성분 수 2개
n = 2
pca = PCA(n_components = n) # 2차원으로 축소

# 만들고, 적용하기(결과는 넘파이 어레이)
x2_pc = pca.fit_transform(x2)


# 2개의 주성분
x2_pc[:5]


# (옵션) 데이터프레임으로 변환
x2_pc = pd.DataFrame(x2_pc, columns = ['PC1', 'PC2'])
x2_pc.head()





pd.concat([iris, x2_pc], axis = 1).head()





sns.scatterplot(x = 'PC1', y = 'PC2', data = x2_pc, hue = y)
plt.grid()
plt.show()











# breast_cancer 데이터 로딩
cancer=load_breast_cancer()
x = cancer.data
y = cancer.target

x = pd.DataFrame(x, columns=cancer.feature_names)

x.shape


x.head()


x.info()


x.describe().T





scaler = MinMaxScaler()
x = scaler.fit_transform(x)

# (옵션)데이터프레임 변환
x = pd.DataFrame(x, columns=cancer.feature_names)








x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .3, random_state = 20)





from sklearn.decomposition import PCA


# feature 수
x_train.shape[1]





# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수)
n = x_train.shape[1] # feautre 수

# 주성분 분석 선언
pca = PCA(n_components=n)

# 만들고, 적용하기
x_train_pc = pca.fit_transform(x_train)
x_val_pc = pca.transform(x_val)





# 칼럼이름 생성
column_names = [ 'PC'+str(i+1) for i in range(n) ]
column_names


# 데이터프레임으로 변환하기
x_train_pc = pd.DataFrame(x_train_pc, columns = column_names)
x_val_pc = pd.DataFrame(x_val_pc, columns = column_names)
x_train_pc








# 주성분 1개짜리
n = 1
pca = PCA(n_components = n) 

# 만들고, 적용하기(결과는 넘파이 어레이)
x_train_pc_1 = pca.fit_transform(x_train)


# 주성분 2개짜리
n = 2
pca = PCA(n_components = n) 

# 만들고, 적용하기(결과는 넘파이 어레이)
x_train_pc_2 = pca.fit_transform(x_train)


# 주성분 3개짜리
n = 3
pca = PCA(n_components = n) 

# 만들고, 적용하기(결과는 넘파이 어레이)
x_train_pc_3 = pca.fit_transform(x_train)





x_train_pc_1[:3]


x_train_pc_2[:3]


x_train_pc_3[:2]


print(x_train_pc_1[:3])
print()
print(x_train_pc_2[:3])
print()
print(x_train_pc_3[:3])





# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수) 
n = x_train.shape[1] 
# 주성분 분석 선언 
pca = PCA(n_components=n) 
# 만들고, 적용하기 
x_train_pc = pca.fit_transform(x_train) 
x_val_pc = pca.transform(x_val)


plt.plot(range(1,n+1), pca.explained_variance_ratio_, marker = '.')
plt.xlabel('No. of PC')
plt.grid()
plt.show()











sns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)
plt.grid()
plt.show()











model0 = KNeighborsClassifier()
model0.fit(x_train, y_train)





x_val = np.array(x_val)


# 원본데이터 모델의 성능
pred0 = model0.predict(x_val)

print(confusion_matrix(y_val, pred0))
print(accuracy_score(y_val, pred0))
print(classification_report(y_val, pred0))








column_names[:2]


cols = column_names[:1]
x_train_pc1 = x_train_pc.loc[:, cols]
x_val_pc1 = x_val_pc.loc[:, cols]


x_train_pc1.shape





x_train_pc1.shape[1]


# KNN 모델링, 주성분 1개로 모델링
model1 = KNeighborsClassifier()
model1.fit(x_train, y_train)


# 원본데이터 모델의 성능
pred1 = model1.predict(x_val)

print(confusion_matrix(y_val, pred1))
print(accuracy_score(y_val, pred1))
print(classification_report(y_val, pred1))





n = 2
# 데이터 준비
cols = column_names[:n]
x_train_pc_n = x_train_pc.loc[:, cols]
x_val_pc_n = x_val_pc.loc[:, cols]

# 모델링
model_n = KNeighborsClassifier()
model_n.fit(x_train_pc_n, y_train)


# 예측
pred_n = model_n.predict(x_val_pc_n)

# 평가
print(confusion_matrix(y_val, pred_n))
print(accuracy_score(y_val, pred_n))
print(classification_report(y_val, pred_n))








from sklearn.manifold import TSNE


# 2차원으로 축소하기
tsne = TSNE(n_components = 2, random_state=20)
x_tsne = tsne.fit_transform(x)

# 사용의 편리함을 위해 DataFrame으로 변환
x_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])


x_tsne.shape





plt.figure(figsize=(6,6))
sns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)
plt.grid()











digits = load_digits()
x = digits.data
y = digits.target

y = pd.Categorical(y)


x.shape





print(x[0].reshape(8,8))


# f, axes = plt.subplots(5, 2, sharey=True, figsize=(16,6))
plt.figure(figsize=(10, 4))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(x[i,:].reshape([8,8]), cmap='gray');





# 최대, 최소값
np.min(x), np.max(x)


# 최대값으로 나누면 Min Max 스케일링이 됩니다.
x = x / 16





# 차원 축소
pca = PCA(n_components=2)
x_pca = pca.fit_transform(x)

# 데이터프레임으로 변환(옵션)
x_pca = pd.DataFrame(x_pca, columns = ['PC1', 'PC2'])


# 시각화
plt.figure(figsize=(8, 8))
sns.scatterplot(x = 'PC1', y = 'PC2', data = x_pca, hue = y)
plt.grid()
plt.show()





tsne = TSNE(n_components = 2, random_state=20)
x_tsne = tsne.fit_transform(x)

# 데이터프레임으로 변환(옵션)
x_tsne = pd.DataFrame(x_tsne, columns = ['T1', 'T2'])


# 시각화
plt.figure(figsize=(8, 8))
sns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)
plt.grid()
plt.show()



