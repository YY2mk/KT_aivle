




















path = 'C:/Users/User/program/mini_pjt/mini_3/실습파일_에이블러용/데이터/'








# from google.colab import drive
# drive.mount('/content/drive')


#path = '/content/drive/MyDrive/project/'











#!pip install -r requirements.txt








import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import joblib 

# 필요한 라이브러리 로딩
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import *








def model_plot(y, pred) : 
    plt.figure(figsize = (12,8))
    plt.scatter(y, pred, alpha=0.4)

    x_l = np.linspace( y.min(), y.max(), 100)
    plt.plot(x_l, x_l, color = 'black', alpha=0.4)

    plt.xlabel("Actual")
    plt.ylabel("Predicted")
    plt.grid()
    plt.show()








train = joblib.load(path + 'train2.pkl')


train.head()




















train.columns


target = '실차량수'


train.drop('단지코드', axis=1, inplace=True)


x = train.drop(target, axis=1)
y = train.loc[:, target]





# 1번 데이터 전처리에서 조치함
train.isna().sum() 





train


drop_dumm = ['건물형태', '난방방식', '승강기설치여부']
x = pd.get_dummies(x, columns=drop_dumm, drop_first=True, dtype=int)


x





x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=2024)





from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_s = scaler.transform(x_train)
x_val_s = scaler.transform(x_val)





model_lr = LinearRegression()
model_rf = RandomForestRegressor()
model_knn = KNeighborsRegressor()
model_dt = DecisionTreeRegressor()


# MAE : 115~178
# MAPE : 0.69~1.51
result = {}
def acc_print(y_, p_):
    print('MAE:', mean_absolute_error(y_, p_)) # 낮을 수록 실제값에 가까움 # 낮을 수록 오차가 적음
    print('='*60)
    print('MSE:', mean_squared_error(y_, p_)) # 낮을 수록 실제값에 가까움 #제곱 평균
    print('='*60)
    print('MSPE:', mean_absolute_percentage_error(y_, p_)) # 낮을 수록 실제값에 가까움 #MSE의 제곱근
    print('='*60)
    print('R2:', r2_score(y_, p_)) #결정계수 1에 가까울 수록 좋음
    print('='*60)

    return r2_score(y_, p_)


def modle_mk(modle_select, x_train, y_train, x_val, y_val):
    if modle_select == model_rf:
        name = 'Random Forest'
    if modle_select == model_lr:
        name = 'LinearRegression'
    if modle_select == model_knn:
        name = 'KNeighborsRegressor'
    if modle_select == model_dt:
        name = 'DecisionTreeRegressor'
    
    print("model_name:", name)
    model = modle_select
    model.fit(x_train, y_train)
    p1 = model.predict(x_val)

    r = acc_print(y_val, p1)
    result[name] = r

    return result


# LinearRegression 
modle_mk(model_lr, x_train, y_train, x_val, y_val)





# Random Forest
modle_mk(model_rf, x_train, y_train, x_val, y_val) 





# DecisionTreeRegressor
modle_mk(model_dt, x_train, y_train, x_val, y_val) 





#KNeighborsRegressor
modle_mk(model_knn, x_train_s, y_train, x_val_s, y_val) 








result











new_data = joblib.load(path + 'test2.pkl')


new_data





drop_cols = ['단지코드', '지역']
new_data.drop(drop_cols, axis=1, inplace=True)


new_data


dumm_cols = ['건물형태',	'난방방식', '승강기설치여부']
new_data = pd.get_dummies(new_data, columns=dumm_cols, drop_first=True, dtype=int)
new_data.drop('실차량수', axis=1, inplace=True)
new_data


drop_cols = ['30이하', '40이하',	'50이하', '60이하', '70이하', '80이하', '90이하', '100이하', '110이하', '120이하', '121이상']
x_train = x_train.drop(drop_cols, axis=1)
x_train





modle_mk(model_dt, x_train, y_train, new_data, y_val) 



