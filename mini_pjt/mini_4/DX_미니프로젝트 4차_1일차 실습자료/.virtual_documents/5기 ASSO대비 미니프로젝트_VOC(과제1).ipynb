








# 코드실행시 경고 메시지 무시
import warnings
warnings.filterwarnings(action='ignore')











# 여기에 답안코드를 작성하세요.
!pip install seaborn





# 여기에 답안코드를 작성하세요.
import numpy as np
import pandas as pd





# 여기에 답안코드를 작성하세요.
import seaborn as sns
import matplotlib.pyplot as plt











# 여기에 답안코드를 작성하세요.
df = pd.read_csv('voc_data.csv')











# 여기에 답안코드를 작성하세요.
df.head()


# 여기에 답안코드를 작성하세요.
df.tail()





# 여기에 답안코드를 작성하세요.
df.info()





# 여기에 답안코드를 작성하세요.
df.index





# 여기에 답안코드를 작성하세요.
df.columns





# 여기에 답안코드를 작성하세요.
df.values





# 여기에 답안코드를 작성하세요.
df.describe()





# 여기에 답안코드를 작성하세요.
df.isna().sum()





# 여기에 답안코드를 작성하세요.
df['voc_trt_perd_itg_cd']





# 여기에 답안코드를 작성하세요.
df['voc_trt_perd_itg_cd'].value_counts()











# 여기에 답안코드를 작성하세요.
voc_mean = df['voc_trt_perd_itg_cd'].str.count('_').sum() / len(df)
print(voc_mean)

df1 = df.drop('voc_trt_perd_itg_cd', axis=1)





# 여기에 답안코드를 작성하세요.
drop_cols = ['voc_trt_reslt_itg_cd', 'oos_cause_type_itg_cd', 'engt_cperd_type_itg_cd', 'engt_tgt_div_itg_cd', 'fclt_oos_yn']
df1.drop(drop_cols, axis=1, inplace=True)





# 여기에 답안코드를 작성하세요.
df1['cust_clas_itg_cd'].str.count('_').sum()





# 여기에 답안코드를 작성하세요.
df2 = df1.replace({'_': None})





# 여기에 답안코드를 작성하세요.
df.isna().sum()





# 여기에 답안코드를 작성하세요.
df.info()





# 여기에 답안코드를 작성하세요.
df2['cust_clas_itg_cd'] = df2['cust_clas_itg_cd'].fillna(df2['cust_clas_itg_cd'].mode()[0])
df3 = df2.copy()





# 여기에 답안코드를 작성하세요.
df3['age_itg_cd'] = df3['age_itg_cd'].fillna(df3['age_itg_cd'].median())
df4 = df3.copy()





# 여기에 답안코드를 작성하세요.
df4['cont_sttus_itg_cd'] = df4['cont_sttus_itg_cd'].fillna(df4['cont_sttus_itg_cd'].mode()[0])
df5 = df4.copy()





# 여기에 답안코드를 작성하세요.
df5['cust_dtl_ctg_itg_cd'] = df5['cust_dtl_ctg_itg_cd'].fillna(df5['cust_dtl_ctg_itg_cd'].mode()[0])





# 여기에 답안코드를 작성하세요.
df5.info()
drop_cols = ['new_date', 'opn_nfl_chg_date', 'cont_fns_pam_date']
df5.drop(drop_cols, axis=1, inplace=True)





# 여기에 답안코드를 작성하세요.
df5.drop('voc_mis_pbls_yn', axis=1, inplace=True)








# 여기에 답안코드를 작성하세요.
from sklearn.preprocessing import LabelEncoder

dump_cols = ['cust_clas_itg_cd', 'age_itg_cd', 'cont_sttus_itg_cd', 'cust_dtl_ctg_itg_cd', 'trm_yn']
cat_cols = df5.select_dtypes(include='object')

label_cols = LabelEncoder()
df5['cust_clas_itg_cd'] = label_cols.fit_transform(cat_cols['cust_clas_itg_cd'])





# 여기에 답안코드를 작성하세요.
df6 = pd.get_dummies(df5, columns=dump_cols, drop_first=True, dtype=int)
df6.info()


df6.info()








# 여기에 답안코드를 작성하세요.
from sklearn.model_selection import train_test_split

target = 'trm_yn_Y' 
x = df6.drop(target, axis=1)
y = df6.loc[:, target]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=42, stratify=y)











# 여기에 답안코드를 작성하세요.
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_trin = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)











# 여기에 답안코드를 작성하세요.
from sklearn.linear_model import LogisticRegression

model_lr = LogisticRegression(C=10, max_iter=2000)
model_lr.fit(x_train, y_train)
model_lr.score(x_test, y_test)





# 여기에 답안코드를 작성하세요.
from sklearn.metrics import *
import matplotlib.pyplot as plt
import seaborn as sns

pred = model_lr.predict(x_test)
print(confusion_matrix(pred, y_test))
sns.heatmap(confusion_matrix(pred, y_test), annot=True, fmt='.2f')
plt.show()
print(classification_report(pred, y_test))





# 여기에 답안코드를 작성하세요.
from sklearn.tree import DecisionTreeClassifier

model_lr = DecisionTreeClassifier(max_depth=10, random_state=42)
model_lr.fit(x_train, y_train)
model_lr.score(x_test, y_test)





# 여기에 답안코드를 작성하세요.
from sklearn.ensemble import RandomForestClassifier

model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
model_rf.fit(x_train, y_train)
model_lr.score(x_test, y_test)





# 여기에 답안코드를 작성하세요.
from xgboost import XGBClassifier

model_xgb = XGBClassifier(n_estimators=5)
model_xgb.fit(x_train, y_train)
model_lr.score(x_test, y_test)





# 여기에 답안코드를 작성하세요.
from lightgbm import LGBMClassifier
 
model_lgbm = LGBMClassifier(n_estimators=3)
model_lgbm.fit(x_train, y_train)
model_lgbm.score(x_test, y_test)





# 이 데이터로 연습하세요.
x_data = np.array([1.6, 2.3, 3.5, 4.6]).reshape(-1,1)
y_data = np.array([3.3, 5.5, 7.2, 9.9])


# 여기에 답안코드를 작성하세요.
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(x_data, y_data)














# 여기에 답안코드를 작성하세요.
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

n = x_train.shape[1]
model = Sequential([Dense(64, input_shape=(n, ), activation='relu'),
                    Dense(32, activation='relu'),
                    Dense(16, activation='relu'),
                    Dropout(0.2),
                    Dense(1, activation='sigmoid')
                   ])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
es = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)
mcp = ModelCheckpoint('best_model.keras', monitor='val_loss', verbose=1, save_best_only=True)

history = model.fit(x_train, y_train, epochs=10, batch_size=10, callbacks=[es, mcp], validation_data=(x_test, y_test))





# 여기에 답안코드를 작성하세요.
from keras.utils import to_categorical

y_train_oh = to_categorical(y_train)
y_test_oh = to_categorical(y_test)

model = Sequential([Dense(64, input_shape=(n, ), activation='relu'),
                    Dense(32, activation='relu'),
                    Dense(16, activation='relu'),
                    Dropout(0.2),
                    Dense(2, activation='softmax')
                   ])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])
history = model.fit(x_train, y_train_oh, batch_size=10, epochs=10, callbacks=[es,mcp], validation_data=(x_test, y_test_oh), verbose=1)


# 참고
# Y 레이블 One-Hot-Encoding 되지 않았으면 loss='sparse_categorical_crossentropy' 사용
# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['acc'])
# history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[es,mc], validation_data=(X_test, y_test), verbose=1)





# 여기에 답안코드를 작성하세요.
plt.plot(history.history['acc'], label='Train')
plt.plot(history.history['val_acc'], label='Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()
plt.show()





# 여기에 답안코드를 작성하세요.
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()





# 여기에 답안코드를 작성하세요.
y_test_pred = model.predict(x_test)
y_test_pred = np.argmax(y_test_pred, axis=1)
y_test = np.argmax(y_test_oh, axis=1)

print(accuracy_score(y_test, y_test_pred))



